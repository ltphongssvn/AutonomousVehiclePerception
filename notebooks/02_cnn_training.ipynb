{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - CNN Training\n",
    "# AutonomousVehiclePerception/notebooks/02_cnn_training.ipynb\n",
    "\n",
    "Train 2D CNN perception model on KITTI dataset with GPU acceleration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from pathlib import Path\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from src.model.cnn_2d import PerceptionCNN2D\n",
    "from src.model.fpn_resnet import FPNDetector\n",
    "from src.data.kitti_dataset import KITTIDataset\n",
    "from src.data.augmentations import get_train_transforms, get_val_transforms\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {device}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'Memory: {torch.cuda.get_device_properties(0).total_mem / 1e9:.1f} GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training config\n",
    "CONFIG = {\n",
    "    'model': 'cnn_2d',          # 'cnn_2d' or 'fpn_resnet'\n",
    "    'num_classes': 9,            # KITTI classes\n",
    "    'image_size': (480, 640),\n",
    "    'batch_size': 8,\n",
    "    'num_epochs': 50,\n",
    "    'learning_rate': 1e-3,\n",
    "    'weight_decay': 1e-4,\n",
    "    'val_split': 0.2,\n",
    "    'kitti_root': '../data/raw/kitti',\n",
    "    'checkpoint_dir': '../checkpoints',\n",
    "    'log_dir': '../logs/tensorboard',\n",
    "}\n",
    "\n",
    "Path(CONFIG['checkpoint_dir']).mkdir(parents=True, exist_ok=True)\n",
    "Path(CONFIG['log_dir']).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = get_train_transforms(CONFIG['image_size'])\n",
    "val_transforms = get_val_transforms(CONFIG['image_size'])\n",
    "\n",
    "kitti_root = Path(CONFIG['kitti_root'])\n",
    "if kitti_root.exists():\n",
    "    full_dataset = KITTIDataset(root=kitti_root, split='training', transform=train_transforms)\n",
    "    val_size = int(len(full_dataset) * CONFIG['val_split'])\n",
    "    train_size = len(full_dataset) - val_size\n",
    "    train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "    print(f'Train: {train_size}, Val: {val_size}')\n",
    "else:\n",
    "    # Use synthetic data for demonstration\n",
    "    print('KITTI not found. Using synthetic data for demo.')\n",
    "    from torch.utils.data import TensorDataset\n",
    "    X = torch.randn(200, 3, *CONFIG['image_size'])\n",
    "    Y = torch.randint(0, CONFIG['num_classes'], (200, CONFIG['image_size'][0]//16, CONFIG['image_size'][1]//16))\n",
    "    full_dataset = TensorDataset(X, Y)\n",
    "    val_size = int(len(full_dataset) * CONFIG['val_split'])\n",
    "    train_size = len(full_dataset) - val_size\n",
    "    train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "    print(f'Synthetic Train: {train_size}, Val: {val_size}')\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=CONFIG['batch_size'], shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=CONFIG['batch_size'], shuffle=False, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONFIG['model'] == 'cnn_2d':\n",
    "    model = PerceptionCNN2D(num_classes=CONFIG['num_classes'])\n",
    "else:\n",
    "    model = FPNDetector(num_classes=CONFIG['num_classes'], pretrained=True)\n",
    "\n",
    "model = model.to(device)\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'Model: {CONFIG[\"model\"]}')\n",
    "print(f'Parameters: {num_params:,}')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=CONFIG['learning_rate'], weight_decay=CONFIG['weight_decay'])\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=CONFIG['num_epochs'])\n",
    "\n",
    "writer = SummaryWriter(log_dir=CONFIG['log_dir'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, criterion, optimizer, device, epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, batch in enumerate(loader):\n",
    "        if isinstance(batch, (list, tuple)) and len(batch) == 2:\n",
    "            images, targets = batch\n",
    "            if isinstance(targets, dict):\n",
    "                continue  # Skip KITTI dict targets for now\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Resize targets to match output spatial dims if needed\n",
    "        if outputs.shape[2:] != targets.shape[1:]:\n",
    "            targets = torch.nn.functional.interpolate(\n",
    "                targets.unsqueeze(1).float(), size=outputs.shape[2:], mode='nearest'\n",
    "            ).squeeze(1).long()\n",
    "\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correct += (preds == targets).sum().item()\n",
    "        total += targets.numel()\n",
    "\n",
    "    avg_loss = running_loss / max(len(loader), 1)\n",
    "    accuracy = correct / max(total, 1)\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            if isinstance(batch, (list, tuple)) and len(batch) == 2:\n",
    "                images, targets = batch\n",
    "                if isinstance(targets, dict):\n",
    "                    continue\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            images = images.to(device)\n",
    "            targets = targets.to(device)\n",
    "            outputs = model(images)\n",
    "\n",
    "            if outputs.shape[2:] != targets.shape[1:]:\n",
    "                targets = torch.nn.functional.interpolate(\n",
    "                    targets.unsqueeze(1).float(), size=outputs.shape[2:], mode='nearest'\n",
    "                ).squeeze(1).long()\n",
    "\n",
    "            loss = criterion(outputs, targets)\n",
    "            running_loss += loss.item()\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == targets).sum().item()\n",
    "            total += targets.numel()\n",
    "\n",
    "    avg_loss = running_loss / max(len(loader), 1)\n",
    "    accuracy = correct / max(total, 1)\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(CONFIG['num_epochs']):\n",
    "    start = time.time()\n",
    "\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device, epoch)\n",
    "    val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
    "    scheduler.step()\n",
    "\n",
    "    elapsed = time.time() - start\n",
    "\n",
    "    # TensorBoard logging\n",
    "    writer.add_scalar('Loss/train', train_loss, epoch)\n",
    "    writer.add_scalar('Loss/val', val_loss, epoch)\n",
    "    writer.add_scalar('Accuracy/train', train_acc, epoch)\n",
    "    writer.add_scalar('Accuracy/val', val_acc, epoch)\n",
    "    writer.add_scalar('LR', optimizer.param_groups[0]['lr'], epoch)\n",
    "\n",
    "    # Save best checkpoint\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        ckpt_path = Path(CONFIG['checkpoint_dir']) / f'{CONFIG[\"model\"]}_best.pth'\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': val_loss,\n",
    "            'val_acc': val_acc,\n",
    "        }, ckpt_path)\n",
    "\n",
    "    if epoch % 5 == 0 or epoch == CONFIG['num_epochs'] - 1:\n",
    "        print(f'Epoch {epoch:3d}/{CONFIG[\"num_epochs\"]} | '\n",
    "              f'Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | '\n",
    "              f'Val Loss: {val_loss:.4f} Acc: {val_acc:.4f} | '\n",
    "              f'LR: {optimizer.param_groups[0][\"lr\"]:.6f} | '\n",
    "              f'Time: {elapsed:.1f}s')\n",
    "\n",
    "writer.close()\n",
    "print(f'\\nTraining complete. Best val loss: {best_val_loss:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
